{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMAction2 Tutorial.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d3be223906144829273f6fa1ecaa844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b303155bd05244b1af6ae063bca47094",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d93a4b3f9224447da9c155caf92b70cd",
              "IPY_MODEL_f9fbb994848141f0b3bdd1c4ce3d51c2"
            ]
          }
        },
        "b303155bd05244b1af6ae063bca47094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d93a4b3f9224447da9c155caf92b70cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_58008a3ba9384f7ebcdf24b50460c86b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad9f9c0e4e17415280aa304e91d3c825"
          }
        },
        "f9fbb994848141f0b3bdd1c4ce3d51c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_09d76d4bad384feeab50ed9b9a0ee633",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 113MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07cfa99e42c94508870154e436d31e52"
          }
        },
        "58008a3ba9384f7ebcdf24b50460c86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad9f9c0e4e17415280aa304e91d3c825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09d76d4bad384feeab50ed9b9a0ee633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07cfa99e42c94508870154e436d31e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5248p/breed/blob/main/MMAction2_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LqHGkGEVqpm"
      },
      "source": [
        "## MMAction2 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf8PpPXtVvmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cb1115-80a9-4152-8691-2863855d1a61"
      },
      "source": [
        "# cuda, gcc 버전 확인\n",
        "!nvcc -V\n",
        "\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PAJ4ArzV5Ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9a652cf-2daf-4698-8ab6-b9761b2fa8d4"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full==latest+torch1.5.0+cu101 -f https://download.openmmlab.com/mmcv/dist/index.html\n",
        "\n",
        "# Install mmaction2\n",
        "!rm -rf mmaction2\n",
        "!git clone https://github.com/open-mmlab/mmaction2.git\n",
        "%cd mmaction2\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# Install some optional requirements\n",
        "!pip install -r requirements/optional.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/index.html\n",
            "Collecting mmcv-full==latest+torch1.5.0+cu101\n",
            "\u001b[?25l  Downloading https://download.openmmlab.com/mmcv/dist/latest/torch1.5.0/cu101/mmcv_full-latest%2Btorch1.5.0%2Bcu101-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K     |████████████████████████████████| 23.6MB 139kB/s \n",
            "\u001b[?25hCollecting yapf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/5d/d84677fe852bc5e091739acda444a9b6700ffc6b11a21b00dd244c8caef0/yapf-0.30.0-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 16.3MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (7.0.0)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.2.7 yapf-0.30.0\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 9306 (delta 0), reused 0 (delta 0), pack-reused 9301\u001b[K\n",
            "Receiving objects: 100% (9306/9306), 35.30 MiB | 41.94 MiB/s, done.\n",
            "Resolving deltas: 100% (6600/6600), done.\n",
            "/content/mmaction2\n",
            "Obtaining file:///content/mmaction2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (7.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->mmaction2==0.11.0) (1.15.0)\n",
            "Installing collected packages: mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "Successfully installed mmaction2\n",
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/b7/4b1095af7f8e87c0f54fc0a3de9472d09583eaf2e904a60f0817819fff11/av-8.0.3-cp36-cp36m-manylinux2010_x86_64.whl (37.2MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 150kB/s \n",
            "\u001b[?25hCollecting decord>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/5e/e2be6a3a3a46275059574d9c6a1d422aa6c7c3cbf6614939b8a3c3f8f2d5/decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 196kB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from -r requirements/optional.txt (line 3)) (0.2.9)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from -r requirements/optional.txt (line 4)) (0.8.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (from -r requirements/optional.txt (line 5)) (0.2.3.5)\n",
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/db/608877fea324c3a44aaa50dbcb23ff5b7e3d222a7c5511c19d1651db512e/onnx-1.8.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 256kB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/f009251fd1b91a2e1ce6f22d4b5be9936fbd0072842c5087a2a49706c509/onnxruntime-1.6.0-cp36-cp36m-manylinux2014_x86_64.whl (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 50.0MB/s \n",
            "\u001b[?25hCollecting PyTurboJPEG\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/f5/6106c673096b1bc1af716bbc9b17e542c77ccad5fafd150afb91ff18a6e8/PyTurboJPEG-1.4.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from decord>=0.4.1->-r requirements/optional.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.51.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (2.1.9)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->-r requirements/optional.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->-r requirements/optional.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx->-r requirements/optional.txt (line 6)) (3.12.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug->-r requirements/optional.txt (line 3)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug->-r requirements/optional.txt (line 3)) (2.5)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa->-r requirements/optional.txt (line 4)) (1.14.4)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa->-r requirements/optional.txt (line 4)) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa->-r requirements/optional.txt (line 4)) (53.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (20.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa->-r requirements/optional.txt (line 4)) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (1.24.3)\n",
            "Building wheels for collected packages: PyTurboJPEG\n",
            "  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.4.1-cp36-none-any.whl size=7003 sha256=a6e7c4e4d6ac60a678dded6b3022f55aadd4bb210c1f80a8b889aff5a718a27d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/21/97/152eed6e60d59f1c432139dee7a2e89de44026ef1855b4c4d7\n",
            "Successfully built PyTurboJPEG\n",
            "Installing collected packages: av, decord, onnx, onnxruntime, PyTurboJPEG\n",
            "Successfully installed PyTurboJPEG-1.4.1 av-8.0.3 decord-0.5.2 onnx-1.8.1 onnxruntime-1.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No_zZAFpWC-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50034fc-c829-4705-f12f-89281be3fab0"
      },
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "print(mmaction.__version__)\n",
        "\n",
        "# Check MMCV installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101 True\n",
            "0.11.0\n",
            "10.1\n",
            "GCC 7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXf7oV5DWdab"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64CW6d_AaT-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07100d5b-99db-4f15-e297-037c73b7e23e"
      },
      "source": [
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \\\n",
        "      -O checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘checkpoints’: File exists\n",
            "--2021-02-23 04:38:00--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.35\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNZB7NoSabzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c15798a-4546-40fb-d19f-9e125e03547a"
      },
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = '/content/mmaction2/configs/recognition/tsn/tsn_r50_video_inference_1x1x3_100e_kinetics400_rgb.py'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use load_from_local loader\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEMsBnpHapAn"
      },
      "source": [
        "# Use the recognizer to do inference\n",
        "video = '/content/mmaction2/demo/demo.mp4'\n",
        "label = '/content/mmaction2/demo/label_map_k400.txt'\n",
        "results = inference_recognizer(model, video, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIyJXqfWathq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ac09b9-d7df-4430-a89e-28526b76f3be"
      },
      "source": [
        "# Let's show the results\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arm wrestling:  29.616438\n",
            "rock scissors paper:  10.754841\n",
            "shaking hands:  9.908401\n",
            "clapping:  9.189913\n",
            "massaging feet:  8.305306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuZG8kZ2fJ5d"
      },
      "source": [
        "## 커스텀 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEFyxChfgiJ"
      },
      "source": [
        "먼저 Kinetics-400에서 얻은 데이터 세트를 다운로드 해 보겠습니다. 레이블이있는 동영상 30 개를 훈련 데이터 세트로 선택하고 라벨이있는 동영상 10 개를 테스트 데이터 세트로 선택합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjsUj9JzgUlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c346b61-da3c-4e25-f1bc-df41198130c9"
      },
      "source": [
        "# download, decompress the data\n",
        "!rm kinetics400_tiny.zip*\n",
        "!rm -rf kinetics400_tiny\n",
        "!wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
        "!unzip kinetics400_tiny.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'kinetics400_tiny.zip*': No such file or directory\n",
            "--2021-02-23 04:54:04--  https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.35\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18308682 (17M) [application/zip]\n",
            "Saving to: ‘kinetics400_tiny.zip’\n",
            "\n",
            "kinetics400_tiny.zi 100%[===================>]  17.46M  7.62MB/s    in 2.3s    \n",
            "\n",
            "2021-02-23 04:54:08 (7.62 MB/s) - ‘kinetics400_tiny.zip’ saved [18308682/18308682]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbZ-o7V6hNw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140d17da-7541-4e07-e8e9-a19a0eb1c34d"
      },
      "source": [
        "# Check the directory structure of the tiny data\n",
        "\n",
        "# Install tree first\n",
        "!apt-get -q install tree\n",
        "!tree kinetics400_tiny"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 0s (149 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "kinetics400_tiny\n",
            "├── kinetics_tiny_train_video.txt\n",
            "├── kinetics_tiny_val_video.txt\n",
            "├── train\n",
            "│   ├── 27_CSXByd3s.mp4\n",
            "│   ├── 34XczvTaRiI.mp4\n",
            "│   ├── A-wiliK50Zw.mp4\n",
            "│   ├── D32_1gwq35E.mp4\n",
            "│   ├── D92m0HsHjcQ.mp4\n",
            "│   ├── DbX8mPslRXg.mp4\n",
            "│   ├── FMlSTTpN3VY.mp4\n",
            "│   ├── h10B9SVE-nk.mp4\n",
            "│   ├── h2YqqUhnR34.mp4\n",
            "│   ├── iRuyZSKhHRg.mp4\n",
            "│   ├── IyfILH9lBRo.mp4\n",
            "│   ├── kFC3KY2bOP8.mp4\n",
            "│   ├── LvcFDgCAXQs.mp4\n",
            "│   ├── O46YA8tI530.mp4\n",
            "│   ├── oMrZaozOvdQ.mp4\n",
            "│   ├── oXy-e_P_cAI.mp4\n",
            "│   ├── P5M-hAts7MQ.mp4\n",
            "│   ├── phDqGd0NKoo.mp4\n",
            "│   ├── PnOe3GZRVX8.mp4\n",
            "│   ├── R8HXQkdgKWA.mp4\n",
            "│   ├── RqnKtCEoEcA.mp4\n",
            "│   ├── soEcZZsBmDs.mp4\n",
            "│   ├── TkkZPZHbAKA.mp4\n",
            "│   ├── T_TMNGzVrDk.mp4\n",
            "│   ├── WaS0qwP46Us.mp4\n",
            "│   ├── Wh_YPQdH1Zg.mp4\n",
            "│   ├── WWP5HZJsg-o.mp4\n",
            "│   ├── xGY2dP0YUjA.mp4\n",
            "│   ├── yLC9CtWU5ws.mp4\n",
            "│   └── ZQV4U2KQ370.mp4\n",
            "└── val\n",
            "    ├── 0pVGiAU6XEA.mp4\n",
            "    ├── AQrbRSnRt8M.mp4\n",
            "    ├── b6Q_b7vgc7Q.mp4\n",
            "    ├── ddvJ6-faICE.mp4\n",
            "    ├── IcLztCtvhb8.mp4\n",
            "    ├── ik4BW3-SCts.mp4\n",
            "    ├── jqRrH30V0k4.mp4\n",
            "    ├── SU_x2LQqSLs.mp4\n",
            "    ├── u4Rm6srmIS8.mp4\n",
            "    └── y5Iu7XkTqV0.mp4\n",
            "\n",
            "2 directories, 42 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTdi6dI0hY3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cd5a11-98e1-4442-9232-47e5e9a5760c"
      },
      "source": [
        "# After downloading the data, we need to check the annotation format\n",
        "!cat kinetics400_tiny/kinetics_tiny_train_video.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D32_1gwq35E.mp4 0\n",
            "iRuyZSKhHRg.mp4 1\n",
            "oXy-e_P_cAI.mp4 0\n",
            "34XczvTaRiI.mp4 1\n",
            "h2YqqUhnR34.mp4 0\n",
            "O46YA8tI530.mp4 0\n",
            "kFC3KY2bOP8.mp4 1\n",
            "WWP5HZJsg-o.mp4 1\n",
            "phDqGd0NKoo.mp4 1\n",
            "yLC9CtWU5ws.mp4 0\n",
            "27_CSXByd3s.mp4 1\n",
            "IyfILH9lBRo.mp4 1\n",
            "T_TMNGzVrDk.mp4 1\n",
            "TkkZPZHbAKA.mp4 0\n",
            "PnOe3GZRVX8.mp4 1\n",
            "soEcZZsBmDs.mp4 1\n",
            "FMlSTTpN3VY.mp4 1\n",
            "WaS0qwP46Us.mp4 0\n",
            "A-wiliK50Zw.mp4 1\n",
            "oMrZaozOvdQ.mp4 1\n",
            "ZQV4U2KQ370.mp4 0\n",
            "DbX8mPslRXg.mp4 1\n",
            "h10B9SVE-nk.mp4 1\n",
            "P5M-hAts7MQ.mp4 0\n",
            "R8HXQkdgKWA.mp4 0\n",
            "D92m0HsHjcQ.mp4 0\n",
            "RqnKtCEoEcA.mp4 0\n",
            "LvcFDgCAXQs.mp4 0\n",
            "xGY2dP0YUjA.mp4 0\n",
            "Wh_YPQdH1Zg.mp4 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bq0mxmEi29H"
      },
      "source": [
        "[`VideoDataset`](./datasets/video_dataset.py)에 정의 된 형식에 따라 각 줄은 공백으로 분할 된 파일 경로와 레이블이있는 샘플 동영상을 나타냅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DGJA9jQar"
      },
      "source": [
        "### config 수정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjCcmCKOjktc"
      },
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('/content/mmaction2/demo/configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhu9byjjt-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2635a4-4fae-4edd-e7da-a7465a065639"
      },
      "source": [
        "from mmcv.runner import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'VideoDataset'\n",
        "cfg.data_root = 'kinetics400_tiny/train/'\n",
        "cfg.data_root_val = 'kinetics400_tiny/val/'\n",
        "cfg.ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.ann_file_test = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "\n",
        "cfg.data.test.type = 'VideoDataset'\n",
        "cfg.data.test.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.data.test.data_prefix = 'kinetics400_tiny/val/'\n",
        "\n",
        "cfg.data.train.type = 'VideoDataset'\n",
        "cfg.data.train.ann_file = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.data.train.data_prefix = 'kinetics400_tiny/train/'\n",
        "\n",
        "cfg.data.val.type = 'VideoDataset'\n",
        "cfg.data.val.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.data.val.data_prefix = 'kinetics400_tiny/val/'\n",
        "\n",
        "# The flag is used to determine whether it is omnisource training\n",
        "cfg.setdefault('omnisource', False)\n",
        "# Modify num classes of the model in cls_head\n",
        "cfg.model.cls_head.num_classes = 2\n",
        "# We can use the pre-trained TSN model\n",
        "cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.data.videos_per_gpu = cfg.data.videos_per_gpu // 16\n",
        "cfg.optimizer.lr = cfg.optimizer.lr / 8 / 16\n",
        "cfg.total_epochs = 10\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 10\n",
        "# We can set the log print interval to reduce the the times of printing log\n",
        "cfg.log_config.interval = 5\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='torchvision://resnet50',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=2,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01))\n",
            "train_cfg = None\n",
            "test_cfg = dict(average_clips=None)\n",
            "optimizer = dict(type='SGD', lr=7.8125e-05, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
            "lr_config = dict(policy='step', step=[40, 80])\n",
            "total_epochs = 30\n",
            "checkpoint_config = dict(interval=10)\n",
            "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = 'kinetics400_tiny/train/'\n",
            "data_root_val = 'kinetics400_tiny/val/'\n",
            "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
            "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "ann_file_test = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(1, 0.875, 0.75, 0.66),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=8,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='Flip', flip_ratio=0),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='ThreeCrop', crop_size=256),\n",
            "    dict(type='Flip', flip_ratio=0),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "data = dict(\n",
            "    videos_per_gpu=2,\n",
            "    workers_per_gpu=4,\n",
            "    train=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
            "        data_prefix='kinetics400_tiny/train/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=8),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(1, 0.875, 0.75, 0.66),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix='kinetics400_tiny/val/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=8,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='Flip', flip_ratio=0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix='kinetics400_tiny/val/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='ThreeCrop', crop_size=256),\n",
            "            dict(type='Flip', flip_ratio=0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ]))\n",
            "evaluation = dict(\n",
            "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
            "work_dir = './tutorial_exps'\n",
            "omnisource = False\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES-qnZ3k38Z"
      },
      "source": [
        "### 새로운 recognizer 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDBWkdDRk6oz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7d3be223906144829273f6fa1ecaa844",
            "b303155bd05244b1af6ae063bca47094",
            "d93a4b3f9224447da9c155caf92b70cd",
            "f9fbb994848141f0b3bdd1c4ce3d51c2",
            "58008a3ba9384f7ebcdf24b50460c86b",
            "ad9f9c0e4e17415280aa304e91d3c825",
            "09d76d4bad384feeab50ed9b9a0ee633",
            "07cfa99e42c94508870154e436d31e52"
          ]
        },
        "outputId": "e847cea7-af0b-4dde-d408-fedeb20419fd"
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "from mmaction.datasets import build_dataset\n",
        "from mmaction.models import build_model\n",
        "from mmaction.apis import train_model\n",
        "\n",
        "import mmcv\n",
        "\n",
        "# Build the dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the recognizer\n",
        "model = build_model(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_model(model, datasets, cfg, distributed=False, validate=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use load_from_torchvision loader\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d3be223906144829273f6fa1ecaa844",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 04:57:28,612 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n",
            "2021-02-23 04:57:28,663 - mmaction - INFO - load checkpoint from ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "2021-02-23 04:57:28,665 - mmaction - INFO - Use load_from_local loader\n",
            "2021-02-23 04:57:28,757 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
            "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "2021-02-23 04:57:28,761 - mmaction - INFO - Start running, host: root@d2ed66d984e6, work_dir: /content/tutorial_exps\n",
            "2021-02-23 04:57:28,762 - mmaction - INFO - workflow: [('train', 1)], max: 30 epochs\n",
            "/content/mmaction2/mmaction/core/evaluation/eval_hooks.py:129: UserWarning: runner.meta is None. Creating a empty one.\n",
            "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
            "2021-02-23 04:57:33,029 - mmaction - INFO - Epoch [1][5/15]\tlr: 7.813e-05, eta: 0:06:19, time: 0.852, data_time: 0.633, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6865, loss: 0.6865, grad_norm: 12.7664\n",
            "2021-02-23 04:57:34,086 - mmaction - INFO - Epoch [1][10/15]\tlr: 7.813e-05, eta: 0:03:54, time: 0.211, data_time: 0.006, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.7171, loss: 0.7171, grad_norm: 13.7446\n",
            "2021-02-23 04:57:35,054 - mmaction - INFO - Epoch [1][15/15]\tlr: 7.813e-05, eta: 0:03:02, time: 0.194, data_time: 0.016, memory: 2918, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 0.8884, loss: 0.8884, grad_norm: 14.7141\n",
            "2021-02-23 04:57:39,229 - mmaction - INFO - Epoch [2][5/15]\tlr: 7.813e-05, eta: 0:03:43, time: 0.819, data_time: 0.612, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6562, loss: 0.6562, grad_norm: 10.5717\n",
            "2021-02-23 04:57:40,337 - mmaction - INFO - Epoch [2][10/15]\tlr: 7.813e-05, eta: 0:03:15, time: 0.222, data_time: 0.023, memory: 2918, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 0.7480, loss: 0.7480, grad_norm: 11.7084\n",
            "2021-02-23 04:57:41,331 - mmaction - INFO - Epoch [2][15/15]\tlr: 7.813e-05, eta: 0:02:54, time: 0.199, data_time: 0.022, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6735, loss: 0.6735, grad_norm: 12.8066\n",
            "2021-02-23 04:57:45,545 - mmaction - INFO - Epoch [3][5/15]\tlr: 7.813e-05, eta: 0:03:17, time: 0.827, data_time: 0.615, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7218, loss: 0.7218, grad_norm: 12.4893\n",
            "2021-02-23 04:57:46,882 - mmaction - INFO - Epoch [3][10/15]\tlr: 7.813e-05, eta: 0:03:04, time: 0.267, data_time: 0.073, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6188, loss: 0.6188, grad_norm: 11.8111\n",
            "2021-02-23 04:57:47,764 - mmaction - INFO - Epoch [3][15/15]\tlr: 7.813e-05, eta: 0:02:49, time: 0.176, data_time: 0.002, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7298, loss: 0.7298, grad_norm: 12.5043\n",
            "2021-02-23 04:57:52,082 - mmaction - INFO - Epoch [4][5/15]\tlr: 7.813e-05, eta: 0:03:04, time: 0.848, data_time: 0.617, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6833, loss: 0.6833, grad_norm: 10.1043\n",
            "2021-02-23 04:57:53,139 - mmaction - INFO - Epoch [4][10/15]\tlr: 7.813e-05, eta: 0:02:53, time: 0.212, data_time: 0.008, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6640, loss: 0.6640, grad_norm: 11.7603\n",
            "2021-02-23 04:57:54,076 - mmaction - INFO - Epoch [4][15/15]\tlr: 7.813e-05, eta: 0:02:42, time: 0.187, data_time: 0.010, memory: 2918, top1_acc: 0.3000, top5_acc: 1.0000, loss_cls: 0.7373, loss: 0.7373, grad_norm: 13.6273\n",
            "2021-02-23 04:57:58,236 - mmaction - INFO - Epoch [5][5/15]\tlr: 7.813e-05, eta: 0:02:52, time: 0.817, data_time: 0.589, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6309, loss: 0.6309, grad_norm: 11.1860\n",
            "2021-02-23 04:57:59,441 - mmaction - INFO - Epoch [5][10/15]\tlr: 7.813e-05, eta: 0:02:44, time: 0.239, data_time: 0.019, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7178, loss: 0.7178, grad_norm: 12.4261\n",
            "2021-02-23 04:58:00,581 - mmaction - INFO - Epoch [5][15/15]\tlr: 7.813e-05, eta: 0:02:37, time: 0.230, data_time: 0.053, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7094, loss: 0.7094, grad_norm: 12.4626\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.9 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 04:58:02,430 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-02-23 04:58:02,431 - mmaction - INFO - \n",
            "top1_acc\t0.7000\n",
            "top5_acc\t1.0000\n",
            "2021-02-23 04:58:02,431 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-02-23 04:58:02,437 - mmaction - INFO - \n",
            "mean_acc\t0.7000\n",
            "2021-02-23 04:58:02,738 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
            "2021-02-23 04:58:02,740 - mmaction - INFO - Best top1_acc is 0.7000 at 5 epoch.\n",
            "2021-02-23 04:58:02,741 - mmaction - INFO - Epoch(val) [5][15]\ttop1_acc: 0.7000, top5_acc: 1.0000, mean_class_accuracy: 0.7000\n",
            "2021-02-23 04:58:07,372 - mmaction - INFO - Epoch [6][5/15]\tlr: 7.813e-05, eta: 0:02:46, time: 0.922, data_time: 0.710, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6695, loss: 0.6695, grad_norm: 11.0187\n",
            "2021-02-23 04:58:08,397 - mmaction - INFO - Epoch [6][10/15]\tlr: 7.813e-05, eta: 0:02:39, time: 0.205, data_time: 0.003, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6824, loss: 0.6824, grad_norm: 11.8888\n",
            "2021-02-23 04:58:09,288 - mmaction - INFO - Epoch [6][15/15]\tlr: 7.813e-05, eta: 0:02:32, time: 0.178, data_time: 0.001, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6869, loss: 0.6869, grad_norm: 13.7283\n",
            "2021-02-23 04:58:13,571 - mmaction - INFO - Epoch [7][5/15]\tlr: 7.813e-05, eta: 0:02:37, time: 0.839, data_time: 0.622, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6459, loss: 0.6459, grad_norm: 10.8088\n",
            "2021-02-23 04:58:14,691 - mmaction - INFO - Epoch [7][10/15]\tlr: 7.813e-05, eta: 0:02:31, time: 0.224, data_time: 0.005, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.6004, loss: 0.6004, grad_norm: 9.5419\n",
            "2021-02-23 04:58:15,640 - mmaction - INFO - Epoch [7][15/15]\tlr: 7.813e-05, eta: 0:02:25, time: 0.192, data_time: 0.006, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6829, loss: 0.6829, grad_norm: 12.0927\n",
            "2021-02-23 04:58:20,020 - mmaction - INFO - Epoch [8][5/15]\tlr: 7.813e-05, eta: 0:02:30, time: 0.860, data_time: 0.649, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6921, loss: 0.6921, grad_norm: 13.1960\n",
            "2021-02-23 04:58:21,348 - mmaction - INFO - Epoch [8][10/15]\tlr: 7.813e-05, eta: 0:02:25, time: 0.266, data_time: 0.077, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6074, loss: 0.6074, grad_norm: 11.3316\n",
            "2021-02-23 04:58:22,218 - mmaction - INFO - Epoch [8][15/15]\tlr: 7.813e-05, eta: 0:02:19, time: 0.174, data_time: 0.001, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7029, loss: 0.7029, grad_norm: 12.4475\n",
            "2021-02-23 04:58:26,562 - mmaction - INFO - Epoch [9][5/15]\tlr: 7.813e-05, eta: 0:02:23, time: 0.853, data_time: 0.624, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.5369, loss: 0.5369, grad_norm: 8.3865\n",
            "2021-02-23 04:58:27,759 - mmaction - INFO - Epoch [9][10/15]\tlr: 7.813e-05, eta: 0:02:18, time: 0.239, data_time: 0.037, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6798, loss: 0.6798, grad_norm: 12.8052\n",
            "2021-02-23 04:58:28,657 - mmaction - INFO - Epoch [9][15/15]\tlr: 7.813e-05, eta: 0:02:13, time: 0.179, data_time: 0.002, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5711, loss: 0.5711, grad_norm: 9.9653\n",
            "2021-02-23 04:58:32,928 - mmaction - INFO - Epoch [10][5/15]\tlr: 7.813e-05, eta: 0:02:15, time: 0.838, data_time: 0.627, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5379, loss: 0.5379, grad_norm: 8.8819\n",
            "2021-02-23 04:58:34,176 - mmaction - INFO - Epoch [10][10/15]\tlr: 7.813e-05, eta: 0:02:11, time: 0.250, data_time: 0.042, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.6643, loss: 0.6643, grad_norm: 12.6145\n",
            "2021-02-23 04:58:35,074 - mmaction - INFO - Epoch [10][15/15]\tlr: 7.813e-05, eta: 0:02:06, time: 0.179, data_time: 0.003, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.7041, loss: 0.7041, grad_norm: 12.4945\n",
            "2021-02-23 04:58:35,151 - mmaction - INFO - Saving checkpoint at 10 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.8 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 04:58:37,326 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-02-23 04:58:37,328 - mmaction - INFO - \n",
            "top1_acc\t0.9000\n",
            "top5_acc\t1.0000\n",
            "2021-02-23 04:58:37,329 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-02-23 04:58:37,330 - mmaction - INFO - \n",
            "mean_acc\t0.9000\n",
            "2021-02-23 04:58:37,706 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
            "2021-02-23 04:58:37,707 - mmaction - INFO - Best top1_acc is 0.9000 at 10 epoch.\n",
            "2021-02-23 04:58:37,708 - mmaction - INFO - Epoch(val) [10][15]\ttop1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000\n",
            "2021-02-23 04:58:41,942 - mmaction - INFO - Epoch [11][5/15]\tlr: 7.813e-05, eta: 0:02:08, time: 0.845, data_time: 0.634, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5357, loss: 0.5357, grad_norm: 8.8110\n",
            "2021-02-23 04:58:43,033 - mmaction - INFO - Epoch [11][10/15]\tlr: 7.813e-05, eta: 0:02:04, time: 0.219, data_time: 0.003, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5831, loss: 0.5831, grad_norm: 10.5955\n",
            "2021-02-23 04:58:43,918 - mmaction - INFO - Epoch [11][15/15]\tlr: 7.813e-05, eta: 0:02:00, time: 0.177, data_time: 0.002, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6231, loss: 0.6231, grad_norm: 11.3667\n",
            "2021-02-23 04:58:48,346 - mmaction - INFO - Epoch [12][5/15]\tlr: 7.813e-05, eta: 0:02:01, time: 0.869, data_time: 0.662, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5702, loss: 0.5702, grad_norm: 10.0660\n",
            "2021-02-23 04:58:49,472 - mmaction - INFO - Epoch [12][10/15]\tlr: 7.813e-05, eta: 0:01:58, time: 0.226, data_time: 0.032, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5980, loss: 0.5980, grad_norm: 11.1736\n",
            "2021-02-23 04:58:50,347 - mmaction - INFO - Epoch [12][15/15]\tlr: 7.813e-05, eta: 0:01:54, time: 0.175, data_time: 0.002, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6105, loss: 0.6105, grad_norm: 11.8510\n",
            "2021-02-23 04:58:54,586 - mmaction - INFO - Epoch [13][5/15]\tlr: 7.813e-05, eta: 0:01:54, time: 0.830, data_time: 0.584, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5439, loss: 0.5439, grad_norm: 10.4115\n",
            "2021-02-23 04:58:55,630 - mmaction - INFO - Epoch [13][10/15]\tlr: 7.813e-05, eta: 0:01:51, time: 0.210, data_time: 0.004, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6339, loss: 0.6339, grad_norm: 11.3922\n",
            "2021-02-23 04:58:56,766 - mmaction - INFO - Epoch [13][15/15]\tlr: 7.813e-05, eta: 0:01:47, time: 0.228, data_time: 0.055, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6329, loss: 0.6329, grad_norm: 12.0638\n",
            "2021-02-23 04:59:01,262 - mmaction - INFO - Epoch [14][5/15]\tlr: 7.813e-05, eta: 0:01:48, time: 0.883, data_time: 0.674, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6514, loss: 0.6514, grad_norm: 12.4952\n",
            "2021-02-23 04:59:02,407 - mmaction - INFO - Epoch [14][10/15]\tlr: 7.813e-05, eta: 0:01:45, time: 0.229, data_time: 0.037, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5537, loss: 0.5537, grad_norm: 10.5998\n",
            "2021-02-23 04:59:03,290 - mmaction - INFO - Epoch [14][15/15]\tlr: 7.813e-05, eta: 0:01:41, time: 0.176, data_time: 0.002, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7073, loss: 0.7073, grad_norm: 12.8211\n",
            "2021-02-23 04:59:08,028 - mmaction - INFO - Epoch [15][5/15]\tlr: 7.813e-05, eta: 0:01:42, time: 0.932, data_time: 0.731, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6580, loss: 0.6580, grad_norm: 12.7096\n",
            "2021-02-23 04:59:08,978 - mmaction - INFO - Epoch [15][10/15]\tlr: 7.813e-05, eta: 0:01:38, time: 0.190, data_time: 0.002, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4525, loss: 0.4525, grad_norm: 8.1126\n",
            "2021-02-23 04:59:09,854 - mmaction - INFO - Epoch [15][15/15]\tlr: 7.813e-05, eta: 0:01:35, time: 0.175, data_time: 0.002, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6319, loss: 0.6319, grad_norm: 11.7270\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.9 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 04:59:11,716 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-02-23 04:59:11,718 - mmaction - INFO - \n",
            "top1_acc\t0.8000\n",
            "top5_acc\t1.0000\n",
            "2021-02-23 04:59:11,719 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-02-23 04:59:11,723 - mmaction - INFO - \n",
            "mean_acc\t0.8000\n",
            "2021-02-23 04:59:11,724 - mmaction - INFO - Epoch(val) [15][15]\ttop1_acc: 0.8000, top5_acc: 1.0000, mean_class_accuracy: 0.8000\n",
            "2021-02-23 04:59:15,882 - mmaction - INFO - Epoch [16][5/15]\tlr: 7.813e-05, eta: 0:01:35, time: 0.830, data_time: 0.613, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5428, loss: 0.5428, grad_norm: 10.0100\n",
            "2021-02-23 04:59:17,181 - mmaction - INFO - Epoch [16][10/15]\tlr: 7.813e-05, eta: 0:01:32, time: 0.260, data_time: 0.067, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6094, loss: 0.6094, grad_norm: 11.1874\n",
            "2021-02-23 04:59:18,088 - mmaction - INFO - Epoch [16][15/15]\tlr: 7.813e-05, eta: 0:01:28, time: 0.181, data_time: 0.002, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5310, loss: 0.5310, grad_norm: 9.9070\n",
            "2021-02-23 04:59:22,301 - mmaction - INFO - Epoch [17][5/15]\tlr: 7.813e-05, eta: 0:01:28, time: 0.827, data_time: 0.595, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6308, loss: 0.6308, grad_norm: 12.2662\n",
            "2021-02-23 04:59:23,608 - mmaction - INFO - Epoch [17][10/15]\tlr: 7.813e-05, eta: 0:01:25, time: 0.260, data_time: 0.046, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.6635, loss: 0.6635, grad_norm: 13.0180\n",
            "2021-02-23 04:59:24,506 - mmaction - INFO - Epoch [17][15/15]\tlr: 7.813e-05, eta: 0:01:22, time: 0.181, data_time: 0.003, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.4260, loss: 0.4260, grad_norm: 8.0311\n",
            "2021-02-23 04:59:28,911 - mmaction - INFO - Epoch [18][5/15]\tlr: 7.813e-05, eta: 0:01:22, time: 0.865, data_time: 0.646, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5794, loss: 0.5794, grad_norm: 11.0236\n",
            "2021-02-23 04:59:30,174 - mmaction - INFO - Epoch [18][10/15]\tlr: 7.813e-05, eta: 0:01:19, time: 0.253, data_time: 0.054, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4538, loss: 0.4538, grad_norm: 8.3320\n",
            "2021-02-23 04:59:31,064 - mmaction - INFO - Epoch [18][15/15]\tlr: 7.813e-05, eta: 0:01:16, time: 0.178, data_time: 0.001, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4952, loss: 0.4952, grad_norm: 9.5813\n",
            "2021-02-23 04:59:35,453 - mmaction - INFO - Epoch [19][5/15]\tlr: 7.813e-05, eta: 0:01:15, time: 0.859, data_time: 0.655, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.5533, loss: 0.5533, grad_norm: 10.2659\n",
            "2021-02-23 04:59:36,670 - mmaction - INFO - Epoch [19][10/15]\tlr: 7.813e-05, eta: 0:01:12, time: 0.245, data_time: 0.033, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6117, loss: 0.6117, grad_norm: 11.5430\n",
            "2021-02-23 04:59:37,553 - mmaction - INFO - Epoch [19][15/15]\tlr: 7.813e-05, eta: 0:01:09, time: 0.176, data_time: 0.002, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4129, loss: 0.4129, grad_norm: 7.5688\n",
            "2021-02-23 04:59:41,886 - mmaction - INFO - Epoch [20][5/15]\tlr: 7.813e-05, eta: 0:01:09, time: 0.850, data_time: 0.626, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4327, loss: 0.4327, grad_norm: 8.4843\n",
            "2021-02-23 04:59:42,995 - mmaction - INFO - Epoch [20][10/15]\tlr: 7.813e-05, eta: 0:01:06, time: 0.222, data_time: 0.006, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4622, loss: 0.4622, grad_norm: 8.9760\n",
            "2021-02-23 04:59:43,898 - mmaction - INFO - Epoch [20][15/15]\tlr: 7.813e-05, eta: 0:01:03, time: 0.180, data_time: 0.003, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5917, loss: 0.5917, grad_norm: 11.3904\n",
            "2021-02-23 04:59:43,973 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.8 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 04:59:46,112 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-02-23 04:59:46,114 - mmaction - INFO - \n",
            "top1_acc\t0.9000\n",
            "top5_acc\t1.0000\n",
            "2021-02-23 04:59:46,118 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-02-23 04:59:46,121 - mmaction - INFO - \n",
            "mean_acc\t0.9000\n",
            "2021-02-23 04:59:46,123 - mmaction - INFO - Epoch(val) [20][15]\ttop1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000\n",
            "2021-02-23 04:59:50,193 - mmaction - INFO - Epoch [21][5/15]\tlr: 7.813e-05, eta: 0:01:02, time: 0.813, data_time: 0.598, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4516, loss: 0.4516, grad_norm: 8.3861\n",
            "2021-02-23 04:59:51,491 - mmaction - INFO - Epoch [21][10/15]\tlr: 7.813e-05, eta: 0:00:59, time: 0.260, data_time: 0.044, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4542, loss: 0.4542, grad_norm: 9.1114\n",
            "2021-02-23 04:59:52,409 - mmaction - INFO - Epoch [21][15/15]\tlr: 7.813e-05, eta: 0:00:57, time: 0.184, data_time: 0.003, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5324, loss: 0.5324, grad_norm: 10.5944\n",
            "2021-02-23 04:59:56,616 - mmaction - INFO - Epoch [22][5/15]\tlr: 7.813e-05, eta: 0:00:55, time: 0.824, data_time: 0.590, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5643, loss: 0.5643, grad_norm: 10.7932\n",
            "2021-02-23 04:59:57,979 - mmaction - INFO - Epoch [22][10/15]\tlr: 7.813e-05, eta: 0:00:53, time: 0.275, data_time: 0.070, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5060, loss: 0.5060, grad_norm: 9.9710\n",
            "2021-02-23 04:59:58,922 - mmaction - INFO - Epoch [22][15/15]\tlr: 7.813e-05, eta: 0:00:50, time: 0.188, data_time: 0.016, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4390, loss: 0.4390, grad_norm: 8.7574\n",
            "2021-02-23 05:00:03,375 - mmaction - INFO - Epoch [23][5/15]\tlr: 7.813e-05, eta: 0:00:49, time: 0.875, data_time: 0.654, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6279, loss: 0.6279, grad_norm: 12.5598\n",
            "2021-02-23 05:00:04,422 - mmaction - INFO - Epoch [23][10/15]\tlr: 7.813e-05, eta: 0:00:47, time: 0.210, data_time: 0.010, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.3280, loss: 0.3280, grad_norm: 6.4859\n",
            "2021-02-23 05:00:05,327 - mmaction - INFO - Epoch [23][15/15]\tlr: 7.813e-05, eta: 0:00:44, time: 0.181, data_time: 0.008, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4971, loss: 0.4971, grad_norm: 9.2491\n",
            "2021-02-23 05:00:09,649 - mmaction - INFO - Epoch [24][5/15]\tlr: 7.813e-05, eta: 0:00:42, time: 0.847, data_time: 0.625, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3843, loss: 0.3843, grad_norm: 7.6683\n",
            "2021-02-23 05:00:10,867 - mmaction - INFO - Epoch [24][10/15]\tlr: 7.813e-05, eta: 0:00:40, time: 0.246, data_time: 0.038, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5481, loss: 0.5481, grad_norm: 12.0154\n",
            "2021-02-23 05:00:11,761 - mmaction - INFO - Epoch [24][15/15]\tlr: 7.813e-05, eta: 0:00:38, time: 0.179, data_time: 0.001, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3738, loss: 0.3738, grad_norm: 7.4760\n",
            "2021-02-23 05:00:16,062 - mmaction - INFO - Epoch [25][5/15]\tlr: 7.813e-05, eta: 0:00:36, time: 0.845, data_time: 0.634, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5805, loss: 0.5805, grad_norm: 11.7152\n",
            "2021-02-23 05:00:17,105 - mmaction - INFO - Epoch [25][10/15]\tlr: 7.813e-05, eta: 0:00:34, time: 0.209, data_time: 0.017, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5970, loss: 0.5970, grad_norm: 11.7781\n",
            "2021-02-23 05:00:18,011 - mmaction - INFO - Epoch [25][15/15]\tlr: 7.813e-05, eta: 0:00:31, time: 0.181, data_time: 0.003, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4510, loss: 0.4510, grad_norm: 9.3002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.9 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 05:00:19,869 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-02-23 05:00:19,871 - mmaction - INFO - \n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "2021-02-23 05:00:19,871 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-02-23 05:00:19,875 - mmaction - INFO - \n",
            "mean_acc\t1.0000\n",
            "2021-02-23 05:00:20,177 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_25.pth.\n",
            "2021-02-23 05:00:20,179 - mmaction - INFO - Best top1_acc is 1.0000 at 25 epoch.\n",
            "2021-02-23 05:00:20,181 - mmaction - INFO - Epoch(val) [25][15]\ttop1_acc: 1.0000, top5_acc: 1.0000, mean_class_accuracy: 1.0000\n",
            "2021-02-23 05:00:24,374 - mmaction - INFO - Epoch [26][5/15]\tlr: 7.813e-05, eta: 0:00:30, time: 0.835, data_time: 0.618, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3759, loss: 0.3759, grad_norm: 7.9653\n",
            "2021-02-23 05:00:25,758 - mmaction - INFO - Epoch [26][10/15]\tlr: 7.813e-05, eta: 0:00:27, time: 0.278, data_time: 0.082, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5393, loss: 0.5393, grad_norm: 10.7488\n",
            "2021-02-23 05:00:26,643 - mmaction - INFO - Epoch [26][15/15]\tlr: 7.813e-05, eta: 0:00:25, time: 0.177, data_time: 0.001, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.4193, loss: 0.4193, grad_norm: 8.5493\n",
            "2021-02-23 05:00:30,924 - mmaction - INFO - Epoch [27][5/15]\tlr: 7.813e-05, eta: 0:00:23, time: 0.838, data_time: 0.621, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5921, loss: 0.5921, grad_norm: 11.3992\n",
            "2021-02-23 05:00:31,967 - mmaction - INFO - Epoch [27][10/15]\tlr: 7.813e-05, eta: 0:00:21, time: 0.211, data_time: 0.006, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4482, loss: 0.4482, grad_norm: 9.5257\n",
            "2021-02-23 05:00:32,976 - mmaction - INFO - Epoch [27][15/15]\tlr: 7.813e-05, eta: 0:00:19, time: 0.201, data_time: 0.017, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3865, loss: 0.3865, grad_norm: 8.2025\n",
            "2021-02-23 05:00:37,189 - mmaction - INFO - Epoch [28][5/15]\tlr: 7.813e-05, eta: 0:00:17, time: 0.826, data_time: 0.597, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5439, loss: 0.5439, grad_norm: 11.1966\n",
            "2021-02-23 05:00:38,283 - mmaction - INFO - Epoch [28][10/15]\tlr: 7.813e-05, eta: 0:00:14, time: 0.220, data_time: 0.004, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4841, loss: 0.4841, grad_norm: 9.9195\n",
            "2021-02-23 05:00:39,218 - mmaction - INFO - Epoch [28][15/15]\tlr: 7.813e-05, eta: 0:00:12, time: 0.187, data_time: 0.003, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3131, loss: 0.3131, grad_norm: 6.3338\n",
            "2021-02-23 05:00:43,408 - mmaction - INFO - Epoch [29][5/15]\tlr: 7.813e-05, eta: 0:00:10, time: 0.822, data_time: 0.605, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.3145, loss: 0.3145, grad_norm: 6.6717\n",
            "2021-02-23 05:00:44,536 - mmaction - INFO - Epoch [29][10/15]\tlr: 7.813e-05, eta: 0:00:08, time: 0.226, data_time: 0.032, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.4967, loss: 0.4967, grad_norm: 10.3044\n",
            "2021-02-23 05:00:45,462 - mmaction - INFO - Epoch [29][15/15]\tlr: 7.813e-05, eta: 0:00:06, time: 0.185, data_time: 0.004, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5303, loss: 0.5303, grad_norm: 10.5857\n",
            "2021-02-23 05:00:49,663 - mmaction - INFO - Epoch [30][5/15]\tlr: 7.813e-05, eta: 0:00:04, time: 0.824, data_time: 0.615, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6775, loss: 0.6775, grad_norm: 13.5720\n",
            "2021-02-23 05:00:50,896 - mmaction - INFO - Epoch [30][10/15]\tlr: 7.813e-05, eta: 0:00:02, time: 0.245, data_time: 0.045, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6273, loss: 0.6273, grad_norm: 12.5678\n",
            "2021-02-23 05:00:51,815 - mmaction - INFO - Epoch [30][15/15]\tlr: 7.813e-05, eta: 0:00:00, time: 0.185, data_time: 0.005, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5680, loss: 0.5680, grad_norm: 11.7021\n",
            "2021-02-23 05:00:51,893 - mmaction - INFO - Saving checkpoint at 30 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.7 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 05:00:54,042 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-02-23 05:00:54,043 - mmaction - INFO - \n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "2021-02-23 05:00:54,044 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-02-23 05:00:54,045 - mmaction - INFO - \n",
            "mean_acc\t1.0000\n",
            "2021-02-23 05:00:54,046 - mmaction - INFO - Epoch(val) [30][15]\ttop1_acc: 1.0000, top5_acc: 1.0000, mean_class_accuracy: 1.0000\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSd7oTLlxIf"
      },
      "source": [
        "로그에서 우리는 훈련 과정을 기본적으로 이해하고 recognizer가 얼마나 잘 훈련되었는지 알 수 있습니다.\n",
        "\n",
        "첫째, ImageNet에서 사전 훈련 된 ResNet-50 backbone이 로드됩니다. 이것은 처음부터 훈련하는 것이 더 많은 비용이 들기 때문에 이미 훈련되어 있는 것을 가져다 사용합니다. 로그는 fc.bias 및 fc.weight를 제외한 ResNet-50 backbone의 모든 weight가 로드되었음을 보여줍니다.\n",
        "\n",
        "둘째, 우리가 사용하는 데이터 세트가 작기 때문에 TSN 모델을 동작 인식을 위해 finetune했습니다. 원래 TSN은 400 개의 클래스가 포함 된 원래 Kinetics-400 데이터 세트에서 학습되지만 Kinetics-400 Tiny 데이터 세트에는 2 개의 클래스 만 있습니다. 따라서 분류를 위해 사전 훈련 된 TSN의 마지막 FC layer는 weight 모양이 다르며 사용되지 않습니다.\n",
        "\n",
        "셋째, 훈련 후 recognizer는 기본 평가로 평가됩니다. 결과는 recognizer가 val 데이터 세트에서 100 % top1 정확도와 100 % top5 정확도를 달성 함을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVoSfZVmogw"
      },
      "source": [
        "## 예측 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyY3hCMwyTct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bff3630-29ca-4332-9978-fabaaba159c8"
      },
      "source": [
        "from mmaction.apis import single_gpu_test\n",
        "from mmaction.datasets import build_dataloader\n",
        "from mmcv.parallel import MMDataParallel\n",
        "\n",
        "# Build a test dataloader\n",
        "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
        "data_loader = build_dataloader(\n",
        "        dataset,\n",
        "        videos_per_gpu=1,\n",
        "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "        dist=False,\n",
        "        shuffle=False)\n",
        "model = MMDataParallel(model, device_ids=[0])\n",
        "outputs = single_gpu_test(model, data_loader)\n",
        "\n",
        "eval_config = cfg.evaluation\n",
        "eval_config.pop('interval')\n",
        "eval_res = dataset.evaluate(outputs, **eval_config)\n",
        "for name, val in eval_res.items():\n",
        "    print(f'{name}: {val:.04f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 2.2 task/s, elapsed: 5s, ETA:     0s\n",
            "Evaluating top_k_accuracy ...\n",
            "\n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "\n",
            "Evaluating mean_class_accuracy ...\n",
            "\n",
            "mean_acc\t1.0000\n",
            "top1_acc: 1.0000\n",
            "top5_acc: 1.0000\n",
            "mean_class_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}